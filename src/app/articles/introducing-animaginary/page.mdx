import { ArticleLayout } from '@/components/ArticleLayout'

import cdkDeploymentFlow from './cdk-deployment-flow.png'

export const article = {
  author: 'Nelson Lamounier',
  date: '2025-10-22',
  title:
    'AI Generated My AWS Infrastructure (Then I Had to Optimise It): A Reality Check on Using Kiro for AWS CDK',
  description:
    'I recently generated a full production-ready AWS infrastructure project in about 3 minutes using Kiro, an AI-powered IDE. It was magical. The code was clean, modular, and typed.',
}

export const metadata = {
  title: article.title,
  description: article.description,
}

export default (props) => <ArticleLayout article={article} {...props} />

---

I recently generated a full production-ready AWS infrastructure project in about 3 minutes using Kiro, an AI-powered IDE. It was magical. The code was clean, modular, and typed.

After deploying, I ran into a connection issue. When I asked Kiro for help, he quickly suggested a solution that worked right away.

However, few minutes later, I discovered that this "fix" would have added **$22/month** to my bill for a feature I didn't even need.

Before diving into the details, here is the central lesson from this experience: AI acts as an accelerator but does not replace sound engineering judgment. My ongoing use of Kiro, despite its drawbacks, illustrates this.

In summary, this is a practical story about leveraging AI to build a containerised AWS environment, where it succeeded, where it over-engineered, and how I optimised the output to save over **$260 per year**.

---

## What Kiro Got Right (The "Senior Engineer" in a Box)

Let's start with the good news. I gave Kiro a prompt to build a CDK project for a containerised Node.js app. I asked for cost optimisation (no NAT Gateways), security (no SSH keys), and ARM64 architecture.

```bash
Create an AWS CDK TypeScript project for deploying
a containerised Node.js application with:
- ECS on EC2 (not Fargate) for cost optimization
- ARM64 architecture (t4g instances)
- Public subnet only (no NAT Gateway to minimize costs)
- ECR for container registry
- Systems Manager (SSM) for access (no SSH keys)
- CloudWatch logging
- Modular construct pattern

```

In minutes, Kiro scaffolded a project structure that would have taken me hours to set up manually. It wasn't just "Hello World" code; it was structured like a senior engineer wrote it.

### The Highlights of the Generated Code:

1. **Modular Constructs**: Instead of a giant 500-line file, it separated `vpc-construct.ts`, `ec2-construct.ts`, and `security-construct.ts`.

2. **Security First**: It sets up IAM Roles immediately, adhering to the principle of least privilege. It explicitly denied the use of SSH keys in favour of AWS Systems Manager (SSM).

3. **Cost Awareness**: It correctly identified that t4g.micro (ARM64) instances are cheaper and faster than standard x86 instances, and the Docker build is configured to match that architecture.

```
kiro-cdk-tutorial/
├── bin/
│   └── app.ts                    # CDK app entry point
├── lib/
│   ├── index.ts                  # Main infrastructure stack
│   └── constructs/               # Modular CDK constructs
│       ├── ecr-construct.ts      # Container registry
│       ├── vpc-construct.ts      # Networking (with SSM VPC endpoints)
│       ├── ec2-construct.ts      # Compute instance
│       ├── security-construct.ts # Security groups & IAM
│       └── monitoring-construct.ts # CloudWatch logs & alarms
└──
```

```js
/** @format */

import * as ec2 from "aws-cdk-lib/aws-ec2";
import * as iam from "aws-cdk-lib/aws-iam";
import { Construct } from "constructs";


export interface Ec2ConstructProps {

  vpc: ec2.IVpc;
  securityGroup: ec2.SecurityGroup;
  instanceRole: iam.Role;
}

export class Ec2Construct extends Construct {

  public readonly instance: ec2.Instance;

  constructor(scope: Construct, id: string, props: Ec2ConstructProps) {
    super(scope, id);

    const machineImage = ec2.MachineImage.latestAmazonLinux2023({
      cpuType: ec2.AmazonLinuxCpuType.ARM_64,
    });
    const userData = ec2.UserData.forLinux();
    userData.addCommands(
      "#!/bin/bash",
      "exec > >(tee /var/log/user-data.log) 2>&1",
      "yum update -y",
      "yum install -y docker",
      "systemctl start docker",
      "systemctl enable docker",
      "usermod -a -G docker ec2-user",
      'curl -L "https://github.com/docker/compose/releases/latest/download/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose',
      "chmod +x /usr/local/bin/docker-compose",
      "docker --version",
      "docker-compose --version",
      "systemctl is-active amazon-ssm-agent"
    );

    this.instance = new ec2.Instance(this, "Instance", {
      vpc: props.vpc,
      vpcSubnets: {
        subnetType: ec2.SubnetType.PUBLIC, // Place in public subnet for internet access
      },

      instanceType: ec2.InstanceType.of(
        ec2.InstanceClass.T4G,
        ec2.InstanceSize.MICRO
      ),

      machineImage: machineImage,
      securityGroup: props.securityGroup, // Network firewall rules
      role: props.instanceRole, // IAM permissions for AWS service access

      userData: userData, // Runs on first boot to install Docker
    });
  }
}

```

For a few minutes of effort, I had a deployable stack that cost roughly **$7/month**. I was impressed.

---

## The "Fix" That Cost Me $22/Month

After deploying the stack, I tried to connect to my instance using SSM:

```bash
  {`aws ssm start-session --target <INSTANCE_ID>`}
```

**Result:**

```
Connection timeout.
```

I panicked slightly. Everything looked right. The IAM role was there. The Security Group allowed outbound traffic. I went back to Kiro and pasted the error.

### Kiro's Diagnosis:

> "Your EC2 instance cannot communicate with the Systems Manager service. You should add VPC Endpoints to allow private connectivity."

It generated this code snippet:

```ts
export class VpcConstruct extends Construct {
  public readonly vpc: ec2.IVpc;
  constructor(scope: Construct, id: string, props?: VpcConstructProps) {
    super(scope, id);
    // Rest code the code

    // SSM endpoint - main Systems Manager service
    this.vpc.addInterfaceEndpoint("SSMEndpoint", {
      service: ec2.InterfaceVpcEndpointAwsService.SSM,
      subnets: { subnetType: ec2.SubnetType.PUBLIC },
    });

    // SSM Messages endpoint - for Session Manager
    this.vpc.addInterfaceEndpoint("SSMMessagesEndpoint", {
      service: ec2.InterfaceVpcEndpointAwsService.SSM_MESSAGES,
      subnets: { subnetType: ec2.SubnetType.PUBLIC },
    });

    // EC2 Messages endpoint - for SSM agent communication
    this.vpc.addInterfaceEndpoint("EC2MessagesEndpoint", {
      service: ec2.InterfaceVpcEndpointAwsService.EC2_MESSAGES,
      subnets: { subnetType: ec2.SubnetType.PUBLIC },
    });
  }
}
```

I applied the fix. I deployed. It worked perfectly. I patted myself on the back for "debugging" with AI and moved on.

### The Realization

Weeks later, I looked at my AWS bill. There was a recurring charge for VPC Endpoints.

- 3 Endpoints (SSM, EC2 Messages, SSM Messages)
- $0.01/hour per endpoint
- **Total: ~$22/month**

This meant my hobby project, intended to cost $7/month, suddenly cost **three times as much**.

---

## Understanding What Happened (Why AI Over-Engineered)

Was Kiro wrong? Technically, no.

Adding VPC Endpoints is a valid, secure way to ensure your EC2 instance can talk to AWS services without traversing the public internet. In a strictly private subnet (in an enterprise environment), this is **mandatory**.

However, my architecture used a **Public Subnet**. My EC2 instance had a Public IP and an Internet Gateway.

    **The "Real" Problem:** The instance could actually talk to SSM over the public internet (which is free). The reason my initial connection failed wasn't a networking block; it was simply that the User Data script hadn't finished installing the SSM agent yet.

    I actually just needed to wait **two more minutes** for it to finish.

Kiro solved the problem by handing me the "Enterprise Solution" (VPC Endpoints) instead of the "Patience Solution" (Wait for boot).

{/* DIAGRAM: AWS architecture showing Public Subnet with EC2, Internet Gateway, and unnecessary VPC Endpoints */}

---

## My New Workflow (Generate → Question → Validate)

Now, I follow a three-step process when using AI tools, rather than just applying every fix:

### 1. Generate (The Acceleration)

Use Kiro to build the boilerplate. Let it handle the syntax, the imports, and the IAM policy structures. This saves 80% of the typing time.

### 2. Question (The Context Check)

When the AI suggests a resource, ask:

- Does this incur a simplified hourly cost? (NAT Gateways, Endpoints, and Load Balancers are the usual suspects).
- Is this designed for high compliance (Enterprise) or low cost (Startup)?
- Is there a simpler way?

### 3. Validate (The Optimisation)

Check the implementation against AWS documentation. In my case, a quick check of "SSM prerequisites" would have shown that a Public Subnet + Internet Gateway is a valid, free configuration.

---

## Optimising the Infrastructure

Once I understood the mistake, I went back to the code to optimise it.

### What I Removed:

- Deleted the `InterfaceVpcEndpoint` configuration.
- Removed the associated Security Group rules for those endpoints.

### What I Kept (The Good AI Stuff):

- **ECR Lifecycle Policies**: Kiro correctly set this to keep only 5 images. Without this, storage costs grow indefinitely.
- **ARM64 Architecture**: Keeping the t4g instance saved me 20% on compute.
- **IAM Roles**: I maintained a strict permissions structure, ensuring the instance could communicate only with ECR and CloudWatch.

```ts
export class VpcConstruct extends Construct {
  public readonly vpc: ec2.IVpc;
  constructor(scope: Construct, id: string, props?: VpcConstructProps) {
    super(scope, id);
    this.vpc = new ec2.Vpc(this, "Vpc", {
      maxAzs: props?.maxAzs ?? 1,
      natGateways: props?.natGateways ?? 0,
      subnetConfiguration: [
        {
          cidrMask: 24,
          name: "Public",
          subnetType: ec2.SubnetType.PUBLIC,
          // Automatically assign public IPv4 addresses to instances
          // This is required for instances to be accessible from the internet
          mapPublicIpOnLaunch: true,
        },
      ],
    });
    // No VPC Endpoints needed - using Internet Gateway for AWS service communication
    // This saves $22/month while maintaining SSM connectivity
  }
}
```

### The Financial Result

{/* CHART: Cost comparison showing $29/mo (AI Fix) vs $7/mo (Optimised) */}

I redeployed the stack, waited three minutes for User Data to finish, and the connection succeeded. No functionality was lost, and I saved **$260 a year**.

---

## Guidelines for Responsible AI Engineering

If you are using tools like Kiro, Copilot, or ChatGPT for Infrastructure as Code, adhere to these rules:

### 1. Define Constraints Upfront

Tell the AI, "I am optimising for lowest cost," or "This is a production finance app." Context changes the code it generates.

### 2. Trust Syntax, Verify Architecture

AI is great at writing valid TypeScript. It is mediocre at understanding your budget or specific architectural constraints.

### 3. Monitor Costs Continuously

Don't wait for the monthly bill. Check the AWS Billing Dashboard daily during development to catch "hidden" costs, such as VPC Endpoints or NAT Gateways, early.

### 4. Start Minimal

If AI suggests a complex solution (Load Balancers, Auto Scaling, Endpoints) for a simple problem, strip it back. Add complexity only when you prove you need it.

---

## Conclusion: The Future of Infrastructure Development

So, should you stop using Kiro? **Absolutely not.**

Kiro saved me hours of typing boilerplate, configuring TypeScript, and looking up IAM policy actions. It generated 95% of the project correctly and followed best practices that many juniors miss (like ECR scanning and log retention).

The tool provided incredible value. But **the tool is not the engineer. You are.**

The future of DevOps isn't "AI does everything." It's AI handling the implementation details while humans handle the architectural judgment.

Kiro gave me a production-ready foundation in minutes. My knowledge of AWS fundamentals allowed me to tune that foundation for my specific needs. That combination—**AI speed plus human wisdom**—is how modern infrastructure gets built.

    **Final Savings:** $260/year by understanding when VPC Endpoints are
    actually needed vs. when public internet connectivity is sufficient for AWS
    services.

---

### Resources

- [GitHub Repository with Optimised Code](https://github.com/yourusername/kiro-cdk-optimised)
- [AWS Systems Manager Prerequisites](https://docs.aws.amazon.com/systems-manager/latest/userguide/systems-manager-prereqs.html)
- [AWS VPC Endpoints Pricing](https://aws.amazon.com/privatelink/pricing/)
- [Getting Started with Kiro for AWS CDK Development](/blog/getting-started-kiro-cdk)

---
